from transformers import AutoModelForCausalLM, AutoTokenizer, StoppingCriteria, StoppingCriteriaList
import re

model_path = "./rugpt3small-trained"
model = AutoModelForCausalLM.from_pretrained(model_path)
tokenizer = AutoTokenizer.from_pretrained(model_path)

class ImprovedStopCriteria(StoppingCriteria):
    def __init__(self, tokenizer, min_length=20, max_length=100, stop_sequences=["\n\n", "###"]):
        self.tokenizer = tokenizer
        self.min_length = min_length  # Минимум слов/токенов для генерации
        self.max_length = max_length
        self.stop_sequences = stop_sequences
        
    def __call__(self, input_ids, scores, **kwargs):
        current_text = self.tokenizer.decode(input_ids[0], skip_special_tokens=True)
        
        # 1. Не останавливаемся раньше min_length
        if input_ids.shape[1] < self.min_length:
            return False
            
        # 2. Проверка стоп-последовательностей (только в конце текста)
        if any(current_text.rstrip().endswith(seq) for seq in self.stop_sequences):
            return True
            
        # 3. Останавливаемся на естественных границах (но только после разумной длины)
        last_char = current_text.rstrip()[-1] if current_text.rstrip() else ''
        if input_ids.shape[1] > self.min_length and last_char in {'.', '?', '!'}:
            return True
            
        # 4. Fallback: максимальная длина
        if input_ids.shape[1] >= self.max_length:
            return True
            
        return False

generation_config = {
    "max_new_tokens": 150, 
    "do_sample": True,
    "temperature": 1,
    "top_k": 50,
    "top_p": 0.9,
    "no_repeat_ngram_size": 4,
    "repetition_penalty": 1.5,
    "eos_token_id": tokenizer.eos_token_id,
    "num_beams": 1,
    "stopping_criteria": StoppingCriteriaList([ImprovedStopCriteria(tokenizer)])
}

def generate_response(input_text):
    inputs = tokenizer(input_text, return_tensors="pt")
    output = model.generate(
        **inputs,
        **generation_config
    )
    
    # Декодируем ВЕСЬ текст (включая input)
    full_text = tokenizer.decode(output[0], skip_special_tokens=True)
    
    # Удаляем входной текст, но не обрезая начало ответа
    if full_text.startswith(input_text):
        # Оставляем входной текст + 1 символ (чтобы не оборвать слово)
        response = full_text[len(input_text):].lstrip(" ,.:;")  # Убираем лишние знаки после промпта
    else:
        response = full_text  # На случай, если модель не повторила input
    
    # Постобработка
    response = re.sub(r'\s+([.,!?])', r'\1', response)  # Убираем пробелы перед пунктуацией
    response = response.strip()
    
    # Если ответ начинается с маленькой буквы — исправляем
    if len(response) > 1 and response[0].islower():
        response = response[0].upper() + response[1:]
    
    return response if response else "Не удалось сгенерировать осмысленный ответ."

input_text = "В чём смысл жизни?"
response = generate_response(input_text)
print(response)
